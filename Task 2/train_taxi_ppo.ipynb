{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf01a91",
   "metadata": {},
   "source": [
    "# PPO Taxi-v3 Reinforcement Learning â€“ Training Notebook\n",
    "\n",
    "This notebook trains a PPO (Proximal Policy Optimization) reinforcement learning agent on the Taxi-v3 environment using two learning rates:\n",
    "\n",
    "| Run | Learning Rate | Purpose |\n",
    "|-----|---------------|---------|\n",
    "| Standard Run | 0.0003 | Stable learning |\n",
    "| Aggressive Run | 0.001 | Faster learning but may be unstable |\n",
    "\n",
    "After training, each model is tested over 10 episodes and the total rewards are printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77670a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install stable-baselines3 \"gymnasium[toy-text]\" numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a396954",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cec7e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "STANDARD_LR = 0.0003\n",
    "AGGRESSIVE_LR = 0.001\n",
    "TOTAL_TIMESTEPS = 500_000\n",
    "\n",
    "\n",
    "def make_train_env():\n",
    "    def _make():\n",
    "        env = gym.make(\"Taxi-v3\")\n",
    "        return Monitor(env)\n",
    "    return _make\n",
    "\n",
    "\n",
    "def train_and_test(learning_rate, run_name):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Training PPO on Taxi-v3 | lr={learning_rate} {run_name}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    env = DummyVecEnv([make_train_env()])\n",
    "\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        learning_rate=learning_rate,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        n_steps=2048,\n",
    "        batch_size=64,\n",
    "        ent_coef=0.01,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=TOTAL_TIMESTEPS)\n",
    "    model.save(f\"ppo_taxi_lr_{str(learning_rate).replace('.', '_')}\")\n",
    "\n",
    "    print(\"\\nTesting the trained agent...\")\n",
    "    test_env = gym.make(\"Taxi-v3\")\n",
    "    num_episodes = 10\n",
    "\n",
    "    for ep in range(num_episodes):\n",
    "        obs, info = test_env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            action = int(np.array(action).item())\n",
    "            obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "            total_reward += reward\n",
    "            done = terminated or truncated\n",
    "\n",
    "        print(f\"Episode {ep + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "    test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac5272",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_and_test(STANDARD_LR, \"(standard LR)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56da57",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_and_test(AGGRESSIVE_LR, \"(aggressive LR)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af24805",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "| Run | Learning Rate | Mean Reward | Notes |\n",
    "|-----|---------------|-------------|-------|\n",
    "| Standard LR | 0.0003 | -200 | Agent did not learn but training was stable |\n",
    "| Aggressive LR | 0.001 | ~Mixed | Learned in a few episodes but unstable |\n",
    "\n",
    "Observation:\n",
    "The aggressive LR converged faster in some episodes but caused instability.\n",
    "The standard LR stayed consistent but did not reach high positive reward.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
